import pendulum  
from airflow import DAG, Dataset
from airflow.providers.standard.operators.bash import BashOperator
from airflow.providers.standard.operators.python import PythonOperator


mydataset = Dataset("file:///opt/airflow/data/Churn.csv")

with DAG(
    
    dag_id='producer_2',
    description='Producer de dados para o DAG de consumo_2',
    schedule=None,
    start_date=pendulum.datetime(2025, 1, 1, tz="America/Sao_Paulo"),
    catchup=False,
    tags=['curso', 'exemplo'],
    
) as dag:

    def create_dataset_file():
        df = pd.read_csv("/opt/airflow/data/Churn.csv", sep=';')
        
        df.to_csv("/opt/airflow/data/Churn_new.csv", index=False)
        
    create_dataset_file_task = PythonOperator(
        task_id='create_dataset_file',
        python_callable=create_dataset_file,
        outlets=[mydataset]
    )
    
    create_dataset_file_task
        
        